{
  "parameters": {
    "type": "dataelem.pymodel.vllm_model",
    "decoupled": "1",
    "pymodel_type": "llm.vLLMQwen7bChat",
    "pymodel_params": "{\"temperature\": 0.0, \"stop\": [\"<|im_end|>\", \"<|im_start|>\"]}",
    "gpu_memory": "20",
    "instance_groups": "device=gpu;gpus=0",
    "reload": "1",
    "verbose": "0"
  }
}

