{
  "parameters": {
    "type": "dataelem.pymodel.vllm_model",
    "pymodel_type": "llm.vLLMQwen7bChat",
    "pymodel_params": "{\"gpu_memory_utilization\": 0.6, \"temperature\": 0.0, \"stop\": [\"<|im_end|>\", \"<|im_start|>\"]}",
    "gpu_memory": "30",
    "instance_groups": "device=gpu;gpus=3,8",
    "reload": "1",
    "verbose": "0"
  }
}

