{
  "test_models": ["Baichuan-13B-Chat"],
  "models": ["chatglm2-6b", "Qwen-7B-Chat", "Baichuan-13B-Chat"],
  "load_params": [
    {
      "parameters": {
        "type": "dataelem.pymodel.huggingface_model",
        "pymodel_type": "llm.ChatGLM2",
        "pymodel_params": "{\"max_tokens\": 32768}",
        "gpu_memory": "16",
        "instance_groups": "device=gpu;gpus=7,8"
      }
    },
    {
      "parameters": {
        "type": "dataelem.pymodel.huggingface_model",
        "pymodel_type": "llm.QwenChat",
        "precision": "bf16",
        "gpu_memory": "20",
        "instance_groups": "device=gpu;gpus=7,8",
        "reload": "1"
      }
    },
    {
      "parameters": {
        "type": "dataelem.pymodel.huggingface_model",
        "pymodel_type": "llm.BaichuanChat",
        "pymodel_params":  "{\"max_tokens\": 4096}",
        "gpu_memory": "30",
        "instance_groups": "device=gpu;gpus=7,8",
        "reload": "1"
      }
    }
  ]
}